diff --git a/runtime/hsa-runtime/core/util/lnx/os_linux.cpp b/runtime/hsa-runtime/core/util/lnx/os_linux.cpp
index c6d90f76..b20ae6c3 100644
--- a/runtime/hsa-runtime/core/util/lnx/os_linux.cpp
+++ b/runtime/hsa-runtime/core/util/lnx/os_linux.cpp
@@ -65,7 +65,7 @@
 #include <cpuid.h>
 #endif

-#ifdef __GLIBC__
+#if defined(__GLIBC__) && !defined(__riscv) && !defined(__mips)
 #define ABS_ADDR(base, ptr) (ptr)
 #else
 #define ABS_ADDR(base, ptr) ((base) + (ptr))
diff --git a/runtime/hsa-runtime/core/util/locks.h b/runtime/hsa-runtime/core/util/locks.h
index 6c0de49a..052d04ac 100644
--- a/runtime/hsa-runtime/core/util/locks.h
+++ b/runtime/hsa-runtime/core/util/locks.h
@@ -72,7 +72,11 @@ class HybridMutex {
     while (!lock_.compare_exchange_strong(old, 1)) {
       cnt--;
       if (cnt > maxSpinIterPause) {
+#if defined(_M_X64)
         _mm_pause();
+#else
+        os::YieldThread();
+#endif
       } else if (cnt-- > maxSpinIterYield) {
         os::YieldThread();
       } else {
diff --git a/runtime/hsa-runtime/core/util/utils.h b/runtime/hsa-runtime/core/util/utils.h
index aab828ee..07cf3794 100644
--- a/runtime/hsa-runtime/core/util/utils.h
+++ b/runtime/hsa-runtime/core/util/utils.h
@@ -67,6 +67,24 @@ typedef uint64_t uint64;
 #if defined(__GNUC__)
 #if defined(__i386__) || defined(__x86_64__)
 #include <x86intrin.h>
+#elif defined(__aarch64__)
+#define _mm_clflush(ptr) asm volatile("DMB ish":::"memory")
+#define _mm_sfence(ptr) asm volatile("DMB ishst":::"memory")
+#define _mm_mfence(ptr) asm volatile("DMB ish":::"memory")
+#define _mm_pause() asm volatile("isb")
+#define _mm_lfence(ptr) asm volatile("DMB ish":::"memory")
+#elif defined(__loongarch_lp64)
+#define _mm_clflush(ptr) asm volatile ("dbar 0":::"memory")
+#define _mm_sfence(ptr) asm volatile ("dbar 0":::"memory")
+#define _mm_mfence(ptr) asm volatile ("dbar 0":::"memory")
+#define _mm_pause()  asm volatile ("dbar 0":::"memory")
+#define _mm_lfence(ptr) asm volatile ("dbar 0":::"memory")
+#elif defined(__riscv) && __riscv_xlen == 64
+#define _mm_clflush(ptr) asm volatile("fence rw,rw":::"memory")
+#define _mm_sfence(ptr) asm volatile("fence w,w":::"memory")
+#define _mm_mfence(ptr) asm volatile("fence rw,rw":::"memory")
+#define _mm_pause() asm volatile("fence rw,rw":::"memory")
+#define _mm_lfence(ptr) asm volatile("fence rw,rw":::"memory")
 #endif

 #define __forceinline __inline__ __attribute__((always_inline))
diff --git a/runtime/hsa-runtime/image/util.h b/runtime/hsa-runtime/image/util.h
index 88cdf4cc..4db31e7b 100644
--- a/runtime/hsa-runtime/image/util.h
+++ b/runtime/hsa-runtime/image/util.h
@@ -74,8 +74,8 @@ namespace image {


 #if defined(__GNUC__)
-#include "mm_malloc.h"
 #if defined(__i386__) || defined(__x86_64__)
+#include "mm_malloc.h"
 #include <x86intrin.h>
 #elif defined(__loongarch64)
 #else
